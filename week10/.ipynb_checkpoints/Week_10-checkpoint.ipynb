{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30220b5a-1d7d-45fc-9744-593e4efd5fdc",
   "metadata": {},
   "source": [
    "# Logistic Regression for Identifying Depression Among Students\n",
    "\n",
    "# Overview\n",
    "In this task, you will use Logistic Regression to predict whether a student is experiencing depression based on different factors such as academic pressure, sleep habits, and financial stress. You will go through the full machine learning process, from exploring the data to training and evaluating a model. You are also encouraged to create visualizations to better understand the data and support your analysis.\n",
    "\n",
    "## Dataset\n",
    "We will use the Student Depression Dataset (good timing after mid term exam I guess).\n",
    "\n",
    "### Features:\n",
    "- **Gender**: Male/Female\n",
    "- **Age**: Student’s age\n",
    "- **City**: City where the student lives\n",
    "- **Academic Pressure**: Level of academic stress\n",
    "- **Work Pressure**: Level of work-related stress\n",
    "- **CGPA**: Student’s academic performance\n",
    "- **Study Satisfaction**: How satisfied the student is with their studies\n",
    "- **Job Satisfaction**: Satisfaction with a job (if applicable)\n",
    "- **Sleep Duration**: Sleep hours category (e.g., \"Less than 5 hours\", \"5-6 hours\")\n",
    "- **Dietary Habits**: Eating habits (e.g., Healthy, Moderate)\n",
    "- **Degree**: The degree the student is pursuing\n",
    "- **Suicidal Thoughts**: Whether the student has had suicidal thoughts (Yes/No)\n",
    "- **Work/Study Hours**: Hours spent working or studying daily\n",
    "- **Financial Stress**: Level of financial pressure\n",
    "- **Family History of Mental Illness**: Whether the student has a family history of mental illness (Yes/No)\n",
    "- **Depression**: (Target variable: 1 = Has depression, 0 = No depression)\n",
    "\n",
    "## Tasks\n",
    "### **Use the df DataFrame from the cell below for all tasks.**\n",
    "### Task 1 – Explore the Data\n",
    "    Understand the dataset and find interesting patterns :\n",
    "        - Use basic pandas functions to check the data.\n",
    "        - Look for missing values, outliers, and patterns in the features.\n",
    "        - Create visualizations such as heatmap, histograms, bar charts, scatter plots etc. to explore relationships between different features and depression.\n",
    "\n",
    "### Task 2 – Data Preprocessing\n",
    "    Clean and prepare the data for modeling : \n",
    "        - Handle missing values (e.g., filling or removing them). \n",
    "        - Convert categorical variables into numbers using encoding. \n",
    "        - Normalize or standardize numerical features if needed.\n",
    "        - Explain why you made certain preprocessing choices.\n",
    "\n",
    "### Task 3 – Train the Model\n",
    "    Train a Logistic Regression model to predict depression : \n",
    "        - Split the data into training and testing sets.\n",
    "        - Train a Logistic Regression model using scikit-learn. Look at the different parameters in scikit learn libraries ant try to change some of them (only if you can understand them).\n",
    "        - Make predictions on the test data.\n",
    "\n",
    "### Task 4 – Evaluate the Model\n",
    "    Measure how well the model performs : \n",
    "        - Calculate accuracy, precision, recall, and F1-score.\n",
    "        - Create a confusion matrix to see how often the model makes correct and incorrect predictions.\n",
    "        - Plot an ROC curve to analyze model performance.\n",
    "        - Think on how we could analyse predicted probabilities\n",
    "\n",
    "#### Some documentation \n",
    "\n",
    "[Seaborn Heatmap](https://seaborn.pydata.org/generated/seaborn.heatmap.html)\n",
    "[Pairplot](https://seaborn.pydata.org/generated/seaborn.pairplot.html)\n",
    "(There are many different plots and possible analysis to do with Seaborn. Navigate by yourself and feel free to do some insighful analysis)\n",
    "\n",
    "[Imputing values](https://scikit-learn.org/stable/modules/impute.html)\n",
    "\n",
    "[scikit-learn preprocessing documentation](https://scikit-learn.org/stable/modules/preprocessing.html)\n",
    "\n",
    "[Logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "\n",
    "[Classification metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedfeed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset (assuming it's stored in a CSV file named 'student_depression.csv')\n",
    "df = pd.read_csv('student_depression.csv')\n",
    "\n",
    "# Task 1: Explore the Data\n",
    "# Check for missing values\n",
    "print(\"Missing values:\\n\", df.isnull().sum())\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nDataset statistics:\\n\", df.describe())\n",
    "\n",
    "# Visualize correlations with a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Task 2: Data Preprocessing\n",
    "# Handle missing values (e.g., fill with median)\n",
    "df.fillna(df.median(), inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "\n",
    "# Task 3: Train the Model\n",
    "# Split the data into training and testing sets\n",
    "X = df.drop('Depression', axis=1)\n",
    "y = df['Depression']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Task 4: Evaluate the Model\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# ROC curve\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bdfa79",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Part two\n",
    "\n",
    "### Task 1 – Evaluate and Visualize Metric Changes Across Thresholds\n",
    "    As we have seen in class, different metrics varry according to the threshold. Explain why.\n",
    "\n",
    "    Compute the TN, TP, FN and FP manually. \n",
    "    Find a way to visualise their evolution according to the threshold. \n",
    "    Explain the different variations. What does it tell about your predictions ?\n",
    "\n",
    "    Do the same with evaluation metrics.\n",
    "\n",
    "    How would you define the optimal threshold ?\n",
    "    \n",
    "\n",
    "### Task 2 - Include a financial cost\n",
    "    In the context of predicting student depression, if the model outputs a positive prediction (the student is predicted as being depressed), you must pay for the student to go to the hospital. \n",
    "    This cost is substantial, therefore, it is crucial not only to evaluate the standard classification metrics—such as accuracy, precision, recall, and F1-score—but also to consider the financial implications of your predictions.\n",
    "\n",
    "    Find a way to define the optimal threshold, including the cost of a positive prediction.\n",
    "\n",
    "\n",
    "### Task 3 - Cross validation & hyperparameters optimization\n",
    "    What are the hyperparameters in the logistic regression. \n",
    "    Change your code to find the optimal hyperparameters and train it with cross validation\n",
    "    \n",
    "\n",
    "### Task 4 - Investigate and understand predictions\n",
    "    Now that you have an optimized classification (almost), you want to understand why it predicts some students as depressed.\n",
    "    You might be interested by analysing the difference of feature values for different predicted populations (TP TN FP & FN).\n",
    "    You could also have a look at the weights of you logistic regression.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
